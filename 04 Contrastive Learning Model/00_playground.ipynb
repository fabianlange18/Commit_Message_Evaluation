{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Playground for Developing the Contrastive Learning Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up dataloaders\n",
    "\n",
    "The different possible combinations have to be taken into account. A contrastive learning model can be trained with positive only or positive and negative pairs. The pairs must provide annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "train_data = pd.read_pickle('../data/04a_Train_Set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>author_email</th>\n",
       "      <th>project</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calcs/hazard/event_based/post_processing:\\n\\nM...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>added javadoc heading to hdf5 util class\\n\\n\\n...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>added missing imports in db_tests/__init__.py ...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fixed up a longer-running test, added slow attr</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculators/hazard/event_based/core_next:\\n\\nR...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47433</th>\n",
       "      <td>Fixed \"is a\" op with Ident</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47434</th>\n",
       "      <td>removed old dynamic helper logic from the view...</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>expressjs_express</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47435</th>\n",
       "      <td>fixed property error due to parser not being p...</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47436</th>\n",
       "      <td>Fixed connect middleware for &lt;I&gt;.x</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47437</th>\n",
       "      <td>make Suite#eachTest() private</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>mochajs_mocha</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47438 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  \\\n",
       "0      calcs/hazard/event_based/post_processing:\\n\\nM...   \n",
       "1      added javadoc heading to hdf5 util class\\n\\n\\n...   \n",
       "2      added missing imports in db_tests/__init__.py ...   \n",
       "3        Fixed up a longer-running test, added slow attr   \n",
       "4      calculators/hazard/event_based/core_next:\\n\\nR...   \n",
       "...                                                  ...   \n",
       "47433                         Fixed \"is a\" op with Ident   \n",
       "47434  removed old dynamic helper logic from the view...   \n",
       "47435  fixed property error due to parser not being p...   \n",
       "47436                 Fixed connect middleware for <I>.x   \n",
       "47437                      make Suite#eachTest() private   \n",
       "\n",
       "                author_email            project  label  \n",
       "0      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "1      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "2      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "3      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "4      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "...                      ...                ...    ...  \n",
       "47433     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47434     tj@vision-media.ca  expressjs_express   40.0  \n",
       "47435     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47436     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47437     tj@vision-media.ca      mochajs_mocha   40.0  \n",
       "\n",
       "[47438 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Pairs\n",
    "\n",
    "The code below takes two messages from the same author following each other in the dataset only once to build a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "group_sizes = []\n",
    "training_pairs = []\n",
    "\n",
    "for group in train_data.groupby(\"author_email\"):\n",
    "    group_sizes.append(len(group[1]))\n",
    "    pair = []\n",
    "    for i, message in enumerate(group[1]['message']):\n",
    "        pair.append(message)\n",
    "        if i % 2 == 1:\n",
    "            training_pairs.append(pair)\n",
    "            pair = []\n",
    "\n",
    "positive_training_pairs_count = 0\n",
    "dist_training_pairs = []\n",
    "\n",
    "for size in group_sizes:\n",
    "    positive_training_pairs_count += math.comb(size, 2)\n",
    "    dist_training_pairs.append(math.comb(size, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If every message from one author would be combined with every other message of the same author, the resulting number of training pairs would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51268322"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(28), np.sort(dist_training_pairs))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining every message from one author with every other message from the same author can be achieved with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_training_pairs = []\n",
    "\n",
    "for group in train_data.groupby(\"author_email\"):\n",
    "   for i, message_1 in enumerate(group[1]['message']):\n",
    "       for message_2 in group[1]['message'].iloc[i+1:]:\n",
    "           positive_training_pairs.append([message_1, message_2, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All possible negative pairs could be sampled by combining each message of one author with all messages from all other authors. The amount of possible negative pairs is calculated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "train_data_groups = train_data.groupby(\"author_email\")\n",
    "\n",
    "dataset_size = len(train_data)\n",
    "\n",
    "all_groups = [group for group in train_data_groups]\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message']):\n",
    "        # don't take the groups anymore, that are already taken into consideration once by the first for loop\n",
    "        negative_training_pairs_count += dataset_size - sum([len(train_data_groups.indices[group]) for group in groups_calculated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073889881"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all possible negative pairs would lead to a highly imbalanced training set since there are way less positive pairs. The number of negative pairs needs to be scaled down by a factor of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.946460486848"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = negative_training_pairs_count / positive_training_pairs_count\n",
    "scale_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we cannot directly use this factor because of the different sizes of each group (per author)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to cut the data, but then we need to do it equally for each group. Therefore, we check the minimum amount of messages per author and see, if there would still be enough negative training pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_group_size = math.inf\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    min_group_size = min(min_group_size, len(train_data_groups.indices[group[0]]))\n",
    "\n",
    "min_group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404923050"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message'].iloc[:min_group_size]):\n",
    "        # take the minimum group size for each group that was not yet taken into account by the first loop\n",
    "        negative_training_pairs_count += sum([min_group_size if group[0] not in groups_calculated else 0 for group in all_groups])\n",
    "\n",
    "negative_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still enough messages. That means that we can just cut the amount of messages per author by a certain number and take all possible negative pairs with the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51748200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "cut_amount = 370\n",
    "\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message'].iloc[:cut_amount]):\n",
    "        # take the minimum group size for each group that was not yet taken into account by the first loop\n",
    "        negative_training_pairs_count += sum([cut_amount if group[0] not in groups_calculated else 0 for group in all_groups])\n",
    "\n",
    "negative_training_pairs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0093601269025345"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = negative_training_pairs_count / positive_training_pairs_count\n",
    "scale_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 messages per author are required to build negative pairs that match the positive pairs in amount. Those can be taken randomly to minimize biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_calculated = []\n",
    "\n",
    "negative_training_pairs = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    negative_groups = [group if group[0] not in groups_calculated else None for group in all_groups]\n",
    "    negative_groups = list(filter(lambda item: item is not None, negative_groups))\n",
    "    for j, message_1 in enumerate(group[1]['message'].sample(n=cut_amount)):\n",
    "        for negative_group in negative_groups:\n",
    "            for message_2 in negative_group[1]['message'].sample(n=cut_amount):\n",
    "                count += 1\n",
    "                negative_training_pairs.append([message_1, message_2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51748200"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same scaling is done for validate and test set in the data preparation script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a Model with the Sentence-Transformers framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "MODEL = 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences = [\"This is a sentence\", \"This is another sentence\"]\n",
    "\n",
    "model = SentenceTransformer(MODEL)\n",
    "embedding = model.encode(sentences, convert_to_numpy=False)\n",
    "embeddings = torch.stack(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Tokenization Yourself\n",
    "\n",
    "This requires to not use the sentence-transformer framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial on Using the model without sentence transformers\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenize_function(sentences)\n",
    "\n",
    "embedding = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(embedding, encoding['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the embeddings stay the same no matter whether the sentence-transformers library is used or not, in the second version without sentence-transformers there is the grad_fn=\\<DivBackward0\\> ending."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Distance Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can experiment what target value you need for what input tensors to find the right loss setup for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "x1 = torch.tensor([1, 0])\n",
    "x2 = torch.tensor([0, 1])\n",
    "# 1 if positive pair and -1 if negative pair\n",
    "target = torch.tensor(-1)\n",
    "\n",
    "loss_fn(x1, x2, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss should be minimized. Two completely different input tensors should have a loss of 1 if the corresponding training pair belongs together (=positive pair) and a loss of 0 if not (=negative pair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CosineEmbeddingLoss(margin=0.9)\n",
    "\n",
    "x1 = torch.tensor([1, 1])\n",
    "x2 = torch.tensor([0, 1])\n",
    "# 1 if positive pair and -1 if negative pair\n",
    "target = torch.tensor(-1)\n",
    "\n",
    "loss_fn(x1, x2, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A margin can be applied: It works only on the negative training pairs and reduces the loss by the margin amount."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GPU on Mac M1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the HuggingFace Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset = Dataset.from_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    embedding1 = tokenizer(examples[0], padding=True, truncation=True, return_tensors='pt', max_length=25)\n",
    "    embedding2 = tokenizer(examples[1], padding=True, truncation=True, return_tensors='pt', max_length=25)\n",
    "    return {\"train\" : [embedding1, embedding2, examples[2]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle('../data/04a_Train_Set.pkl')\n",
    "\n",
    "training_pairs = []\n",
    "\n",
    "for i, group in enumerate(train_data.groupby(\"author_email\")):\n",
    "    pair = []\n",
    "    for i, message in enumerate(group[1]['message']):\n",
    "        pair.append(message)\n",
    "        if i % 2 == 1:\n",
    "            pair.append(\"1\")\n",
    "            dict = {\"train\" : pair}\n",
    "            training_pairs.append(dict)\n",
    "            pair = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list(training_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.039494991302490234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 23712,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3d8cd43f1749e4bd2f890dd531c49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23712 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "cannot mix struct and non-struct, non-null values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:189\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    188\u001b[0m     trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     out \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    190\u001b[0m \u001b[39m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: cannot mix struct and non-struct, non-null values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_dataset.py:2975\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2974\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2975\u001b[0m                 writer\u001b[39m.\u001b[39;49mwrite(example)\n\u001b[1;32m   2976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:479\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[0;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhkey_record \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 479\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_examples_on_file()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:437\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     batch_examples[col] \u001b[39m=\u001b[39m [row[\u001b[39m0\u001b[39m][col] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples]\n\u001b[0;32m--> 437\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_batch(batch_examples\u001b[39m=\u001b[39;49mbatch_examples)\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:536\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    535\u001b[0m typed_sequence \u001b[39m=\u001b[39m OptimizedTypedSequence(batch_examples[col], \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mcol_type, try_type\u001b[39m=\u001b[39mcol_try_type, col\u001b[39m=\u001b[39mcol)\n\u001b[0;32m--> 536\u001b[0m arrays\u001b[39m.\u001b[39mappend(pa\u001b[39m.\u001b[39;49marray(typed_sequence))\n\u001b[1;32m    537\u001b[0m inferred_features[col] \u001b[39m=\u001b[39m typed_sequence\u001b[39m.\u001b[39mget_inferred_type()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:236\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:223\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    222\u001b[0m         trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m         \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m pa\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39mArrowInvalid \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: cannot mix struct and non-struct, non-null values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:189\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    188\u001b[0m     trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     out \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    190\u001b[0m \u001b[39m# use smaller integer precisions if possible\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: cannot mix struct and non-struct, non-null values",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/fabian/Developer/HPI/02 Trends AI:DL/04 Contrastive Learning Model/00_playground.ipynb Zelle 56\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fabian/Developer/HPI/02%20Trends%20AI%3ADL/04%20Contrastive%20Learning%20Model/00_playground.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mmap(tokenize_function, input_columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_dataset.py:2585\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2582\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2584\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2586\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2587\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2588\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2589\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2590\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2591\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2592\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2593\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2594\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2595\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2596\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2597\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2598\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2599\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2600\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2601\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2602\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2603\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2604\u001b[0m     )\n\u001b[1;32m   2605\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_dataset.py:585\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    586\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    588\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_dataset.py:552\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    546\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    547\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    548\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    549\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    550\u001b[0m }\n\u001b[1;32m    551\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    553\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    554\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_dataset.py:3005\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   3003\u001b[0m \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3004\u001b[0m     \u001b[39mif\u001b[39;00m writer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3005\u001b[0m         writer\u001b[39m.\u001b[39;49mfinalize()\n\u001b[1;32m   3006\u001b[0m     \u001b[39mif\u001b[39;00m tmp_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m         tmp_file\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:566\u001b[0m, in \u001b[0;36mArrowWriter.finalize\u001b[0;34m(self, close_stream)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[1;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhkey_record \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 566\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_examples_on_file()\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_writer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:437\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols:\n\u001b[1;32m    435\u001b[0m     \u001b[39m# Since current_examples contains (example, key) tuples\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     batch_examples[col] \u001b[39m=\u001b[39m [row[\u001b[39m0\u001b[39m][col] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples]\n\u001b[0;32m--> 437\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_batch(batch_examples\u001b[39m=\u001b[39;49mbatch_examples)\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:536\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    534\u001b[0m     col_try_type \u001b[39m=\u001b[39m try_features[col] \u001b[39mif\u001b[39;00m try_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m col \u001b[39min\u001b[39;00m try_features \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     typed_sequence \u001b[39m=\u001b[39m OptimizedTypedSequence(batch_examples[col], \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mcol_type, try_type\u001b[39m=\u001b[39mcol_try_type, col\u001b[39m=\u001b[39mcol)\n\u001b[0;32m--> 536\u001b[0m     arrays\u001b[39m.\u001b[39mappend(pa\u001b[39m.\u001b[39;49marray(typed_sequence))\n\u001b[1;32m    537\u001b[0m     inferred_features[col] \u001b[39m=\u001b[39m typed_sequence\u001b[39m.\u001b[39mget_inferred_type()\n\u001b[1;32m    538\u001b[0m schema \u001b[39m=\u001b[39m inferred_features\u001b[39m.\u001b[39marrow_schema \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_writer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:236\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:110\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/datasets/arrow_writer.py:223\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m         trying_cast_to_python_objects \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m         \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49marray(cast_to_python_objects(data, only_1d_for_numpy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    224\u001b[0m \u001b[39mexcept\u001b[39;00m pa\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39mArrowInvalid \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39moverflow\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:320\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/array.pxi:39\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: cannot mix struct and non-struct, non-null values"
     ]
    }
   ],
   "source": [
    "dataset.map(tokenize_function, input_columns='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
