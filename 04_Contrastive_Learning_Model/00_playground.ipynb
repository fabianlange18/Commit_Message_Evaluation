{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Playground for Developing the Contrastive Learning Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up dataloaders\n",
    "\n",
    "The different possible combinations have to be taken into account. A contrastive learning model can be trained with positive only or positive and negative pairs. The pairs must provide annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "train_data = pd.read_pickle('../data/04-0a_Train_Set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>author_email</th>\n",
       "      <th>project</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calcs/hazard/event_based/post_processing:\\n\\nM...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>added javadoc heading to hdf5 util class\\n\\n\\n...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>added missing imports in db_tests/__init__.py ...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fixed up a longer-running test, added slow attr</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculators/hazard/event_based/core_next:\\n\\nR...</td>\n",
       "      <td>Lars.Butler@gmail.com</td>\n",
       "      <td>gem_oq-engine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47433</th>\n",
       "      <td>Fixed \"is a\" op with Ident</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47434</th>\n",
       "      <td>removed old dynamic helper logic from the view...</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>expressjs_express</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47435</th>\n",
       "      <td>fixed property error due to parser not being p...</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47436</th>\n",
       "      <td>Fixed connect middleware for &lt;I&gt;.x</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>stylus_stylus</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47437</th>\n",
       "      <td>make Suite#eachTest() private</td>\n",
       "      <td>tj@vision-media.ca</td>\n",
       "      <td>mochajs_mocha</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47438 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message  \\\n",
       "0      calcs/hazard/event_based/post_processing:\\n\\nM...   \n",
       "1      added javadoc heading to hdf5 util class\\n\\n\\n...   \n",
       "2      added missing imports in db_tests/__init__.py ...   \n",
       "3        Fixed up a longer-running test, added slow attr   \n",
       "4      calculators/hazard/event_based/core_next:\\n\\nR...   \n",
       "...                                                  ...   \n",
       "47433                         Fixed \"is a\" op with Ident   \n",
       "47434  removed old dynamic helper logic from the view...   \n",
       "47435  fixed property error due to parser not being p...   \n",
       "47436                 Fixed connect middleware for <I>.x   \n",
       "47437                      make Suite#eachTest() private   \n",
       "\n",
       "                author_email            project  label  \n",
       "0      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "1      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "2      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "3      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "4      Lars.Butler@gmail.com      gem_oq-engine    0.0  \n",
       "...                      ...                ...    ...  \n",
       "47433     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47434     tj@vision-media.ca  expressjs_express   40.0  \n",
       "47435     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47436     tj@vision-media.ca      stylus_stylus   40.0  \n",
       "47437     tj@vision-media.ca      mochajs_mocha   40.0  \n",
       "\n",
       "[47438 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Pairs\n",
    "\n",
    "The code below takes two messages from the same author following each other in the dataset only once to build a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "group_sizes = []\n",
    "training_pairs = []\n",
    "\n",
    "for group in train_data.groupby(\"author_email\"):\n",
    "    group_sizes.append(len(group[1]))\n",
    "    pair = []\n",
    "    for i, message in enumerate(group[1]['message']):\n",
    "        pair.append(message)\n",
    "        if i % 2 == 1:\n",
    "            training_pairs.append(pair)\n",
    "            pair = []\n",
    "\n",
    "positive_training_pairs_count = 0\n",
    "dist_training_pairs = []\n",
    "\n",
    "for size in group_sizes:\n",
    "    positive_training_pairs_count += math.comb(size, 2)\n",
    "    dist_training_pairs.append(math.comb(size, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If every message from one author would be combined with every other message of the same author, the resulting number of training pairs would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51268322"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(28), np.sort(dist_training_pairs))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining every message from one author with every other message from the same author can be achieved with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_training_pairs = []\n",
    "\n",
    "for group in train_data.groupby(\"author_email\"):\n",
    "   for i, message_1 in enumerate(group[1]['message']):\n",
    "       for message_2 in group[1]['message'].iloc[i+1:]:\n",
    "           positive_training_pairs.append([message_1, message_2, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All possible negative pairs could be sampled by combining each message of one author with all messages from all other authors. The amount of possible negative pairs is calculated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "train_data_groups = train_data.groupby(\"author_email\")\n",
    "\n",
    "dataset_size = len(train_data)\n",
    "\n",
    "all_groups = [group for group in train_data_groups]\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message']):\n",
    "        # don't take the groups anymore, that are already taken into consideration once by the first for loop\n",
    "        negative_training_pairs_count += dataset_size - sum([len(train_data_groups.indices[group]) for group in groups_calculated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073889881"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all possible negative pairs would lead to a highly imbalanced training set since there are way less positive pairs. The number of negative pairs needs to be scaled down by a factor of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.946460486848"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = negative_training_pairs_count / positive_training_pairs_count\n",
    "scale_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we cannot directly use this factor because of the different sizes of each group (per author)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to cut the data, but then we need to do it equally for each group. Therefore, we check the minimum amount of messages per author and see, if there would still be enough negative training pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1035"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_group_size = math.inf\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    min_group_size = min(min_group_size, len(train_data_groups.indices[group[0]]))\n",
    "\n",
    "min_group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404923050"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message'].iloc[:min_group_size]):\n",
    "        # take the minimum group size for each group that was not yet taken into account by the first loop\n",
    "        negative_training_pairs_count += sum([min_group_size if group[0] not in groups_calculated else 0 for group in all_groups])\n",
    "\n",
    "negative_training_pairs_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still enough messages. That means that we can just cut the amount of messages per author by a certain number and take all possible negative pairs with the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51748200"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_training_pairs_count = 0\n",
    "\n",
    "cut_amount = 370\n",
    "\n",
    "groups_calculated = []\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    for j, _ in enumerate(group[1]['message'].iloc[:cut_amount]):\n",
    "        # take the minimum group size for each group that was not yet taken into account by the first loop\n",
    "        negative_training_pairs_count += sum([cut_amount if group[0] not in groups_calculated else 0 for group in all_groups])\n",
    "\n",
    "negative_training_pairs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0093601269025345"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = negative_training_pairs_count / positive_training_pairs_count\n",
    "scale_factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 messages per author are required to build negative pairs that match the positive pairs in amount. Those can be taken randomly to minimize biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_calculated = []\n",
    "\n",
    "negative_training_pairs = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i, group in enumerate(train_data_groups):\n",
    "    groups_calculated.append(group[0])\n",
    "    negative_groups = [group if group[0] not in groups_calculated else None for group in all_groups]\n",
    "    negative_groups = list(filter(lambda item: item is not None, negative_groups))\n",
    "    for j, message_1 in enumerate(group[1]['message'].sample(n=cut_amount)):\n",
    "        for negative_group in negative_groups:\n",
    "            for message_2 in negative_group[1]['message'].sample(n=cut_amount):\n",
    "                count += 1\n",
    "                negative_training_pairs.append([message_1, message_2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51748200"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same scaling is done for validate and test set in the data preparation script."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a Model with the Sentence-Transformers framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "MODEL = 'sentence-transformers/all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences = [\"This is a sentence\", \"This is another sentence\"]\n",
    "\n",
    "model = SentenceTransformer(MODEL)\n",
    "embedding = model.encode(sentences, convert_to_numpy=False)\n",
    "embeddings = torch.stack(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Tokenization Yourself\n",
    "\n",
    "This requires to not use the sentence-transformer framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial on Using the model without sentence transformers\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenize_function(sentences)\n",
    "\n",
    "embedding = model(**encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(embedding, encoding['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the embeddings stay the same no matter whether the sentence-transformers library is used or not, in the second version without sentence-transformers there is the grad_fn=\\<DivBackward0\\> ending."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Distance Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can experiment what target value you need for what input tensors to find the right loss setup for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "x1 = torch.tensor([1, 0])\n",
    "x2 = torch.tensor([0, 1])\n",
    "# 1 if positive pair and -1 if negative pair\n",
    "target = torch.tensor(-1)\n",
    "\n",
    "loss_fn(x1, x2, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss should be minimized. Two completely different input tensors should have a loss of 1 if the corresponding training pair belongs together (=positive pair) and a loss of 0 if not (=negative pair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CosineEmbeddingLoss(margin=0.9)\n",
    "\n",
    "x1 = torch.tensor([1, 1])\n",
    "x2 = torch.tensor([0, 1])\n",
    "# 1 if positive pair and -1 if negative pair\n",
    "target = torch.tensor(-1)\n",
    "\n",
    "loss_fn(x1, x2, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A margin can be applied: It works only on the negative training pairs and reduces the loss by the margin amount."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GPU on Mac M1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/installing-pytorch-on-apple-m1-chip-with-gpu-acceleration-3351dc44d67c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the HuggingFace Dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the tokenization before the model in a huggingface dataloader:\n",
    "https://huggingface.co/docs/datasets/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('../data/04-0a_Train_Set.pkl')\n",
    "validate_data = pd.read_pickle('../data/04-0b_Validate_Set.pkl')\n",
    "test_data = pd.read_pickle('../data/04-0c_Test_Set.pkl')\n",
    "\n",
    "messages_1 = []\n",
    "messages_2 = []\n",
    "target = []\n",
    "\n",
    "for i, group in enumerate(train_data.groupby(\"author_email\")):\n",
    "    pair = []\n",
    "    for i, message in enumerate(group[1]['message']):\n",
    "        if i % 2 == 0:\n",
    "            messages_1.append(message)\n",
    "            target.append(1 if random.choice([True, False]) else -1)\n",
    "            training_pairs.append(pair)\n",
    "            pair = []\n",
    "        else:\n",
    "            messages_2.append(message)\n",
    "\n",
    "\n",
    "# Do this when taking a subset to ensure that shuffling happens before taking subsets\n",
    "random.shuffle(training_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23712"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({'message_1': messages_1[:23712], 'messages_2': messages_2, 'target': target[:23712]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "d = {\n",
    "    'train': Dataset.from_dict({'messages_1': messages_1[:23712], 'messages_2': messages_2, 'target': target[:23712]}),\n",
    "    'test': Dataset.from_dict({'messages_1': messages_1[:23712], 'messages_2': messages_2, 'target': target[:23712]})\n",
    "}\n",
    "\n",
    "dataset_dict = DatasetDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02153301239013672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c6821135f2407f9803e986b27841f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02068614959716797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd65a23cc89545ef86901af9ba1be1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021167993545532227,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb40e9e927d46299800eaa5d3e8492c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02102494239807129,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 24,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa132af7d5254e4ab8c2ff2cab721a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL = 'bert-base-cased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    all_features = {}\n",
    "    features_1 = tokenizer(examples['messages_1'], padding='max_length', truncation=True)\n",
    "    features_2 = tokenizer(examples['messages_2'], padding='max_length', truncation=True)\n",
    "    all_features['input_ids_1']      = features_1['input_ids']\n",
    "    all_features['token_type_ids_1'] = features_1['token_type_ids']\n",
    "    all_features['attention_mask_1'] = features_1['attention_mask']\n",
    "    all_features['input_ids_2']      = features_2['input_ids']\n",
    "    all_features['token_type_ids_2'] = features_2['token_type_ids']\n",
    "    all_features['attention_mask_2'] = features_2['attention_mask']\n",
    "    return all_features\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages_1', 'messages_2', 'target', 'input_ids_1', 'token_type_ids_1', 'attention_mask_1', 'input_ids_2', 'token_type_ids_2', 'attention_mask_2'],\n",
       "        num_rows: 23712\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages_1', 'messages_2', 'target', 'input_ids_1', 'token_type_ids_1', 'attention_mask_1', 'input_ids_2', 'token_type_ids_2', 'attention_mask_2'],\n",
       "        num_rows: 23712\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a Model that is not Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "model = AutoConfig.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
